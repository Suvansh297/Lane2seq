

```markdown
# ğŸ›£ï¸ Lane2Seq â€“ Lane Detection Using Transformers

Lane2Seq is a deep learning project that detects **lane lines in road images** using a special kind of model called a **transformer**. Instead of detecting lanes as pixel maps, this model **predicts a sequence of tokens** (like how language models predict text) to represent lane positions.

This project is based on the [TuSimple lane detection dataset](https://github.com/TuSimple/tusimple-benchmark) and uses a **Vision Transformer (ViT)** to understand the image and a transformer decoder to output the lane information as a sequence.

---

## ğŸ§  What Has Been Done

- âœ… Used a **Vision Transformer (ViT)** encoder pretrained using masked autoencoding.
- âœ… Designed a **transformer decoder** to generate tokenized lane positions.
- âœ… Converted lane coordinates into a **token sequence** using a custom tokenizer.
- âœ… Trained the model on the **TuSimple lane dataset**.
- âœ… Added **data augmentation**: random flipping, rotation, scaling, and translation.
- âœ… Implemented **evaluation metrics**: precision, recall, and F1 score.
- âœ… Included **visualizations** for model predictions.
- âœ… Wrote a **configurable pipeline** for training, testing, and debugging.

---

## ğŸ› ï¸ What Has Been Used

- Python & PyTorch
- `transformers` (HuggingFace ViT)
- `safetensors` (to load pretrained ViT safely)
- OpenCV, Pillow (for image handling)
- `tqdm`, `yaml`, `numpy`

---

## ğŸ“¦ Folder Structure


lane2seq\_project/
â”œâ”€â”€ configs/           # YAML configuration
â”œâ”€â”€ models/            # Encoder (ViT) + Decoder
â”œâ”€â”€ datasets/          # Dataset loading and tokenization
â”œâ”€â”€ utils/             # Augmentations, tokenizer, visualizer
â”œâ”€â”€ train1.py          # Main training script
â”œâ”€â”€ inference.py       # Run predictions and save images
â”œâ”€â”€ evaluation.py      # Evaluate model output
â”œâ”€â”€ test\_tokenizer.py  # Visual test for tokenizer



---

## ğŸ§ª How It Works

1. **Images** are passed through a **Vision Transformer (ViT)** that extracts meaningful features.
2. These features go into a **Transformer Decoder** which outputs a sequence of tokens.
3. Tokens represent **lane points**, decoded using a tokenizer.
4. You can then **draw these points** on the original image to see the predicted lanes!

---

## ğŸ–¼ï¸ Example Results

![clips_0530_1492626153155598528_0_20](https://github.com/user-attachments/assets/406aae32-d74f-4d7f-8e6c-af3c7d15139c)



![Lane Prediction Example](path/to/your/image.png)

---

## ğŸš€ How to Use

### 1. Clone the Repo

```bash
git clone https://github.com/yourusername/lane2seq_project.git
cd lane2seq_project


### 2. Install Requirements

```bash
pip install -r requirements.txt


Youâ€™ll need `torch`, `transformers`, `opencv-python`, `Pillow`, `safetensors`, etc.

### 3. Prepare the Dataset

Download the [TuSimple dataset](https://github.com/TuSimple/tusimple-benchmark/issues/3) and place it like this:


archive/TUSimple/
â”œâ”€â”€ train_set/
â”‚   â”œâ”€â”€ clips/
â”‚   â””â”€â”€ label_data_0313.json, ...
â”œâ”€â”€ test_set/
â”‚   â”œâ”€â”€ clips/
â”‚   â””â”€â”€ test_label.json


### 4. Train the Model

```bash
python train1.py


* Best model saved to: `checkpoints/best_model.pth`
* Logs are stored in `logs/train.log`

### 5. Run Inference

```bash
python inference.py


* Outputs: `results/inference/*.json` (lane data) and `*.png` (visual images)

### 6. Evaluate the Model

```bash
python evaluation.py


* Outputs precision, recall, F1 score
* Saves results in `results/inference/evaluation_results.json`

### 7. Debug the Tokenizer (Optional)

```bash
python test_tokenizer.py


* Saves side-by-side visualizations of decoded vs original lanes
* Output in `test_outputs_anchor/`

---

## ğŸ“Œ Configuration

All settings (image size, vocab size, paths, augmentation, etc.) are in:


configs/config.yaml


Change things like number of epochs, checkpoint paths, or augmentation strength from there.

---

## ğŸ“ˆ Metrics Used

* **Precision**: How many predicted lanes are correct?
* **Recall**: How many ground truth lanes are found?
* **F1 Score**: Balance between precision and recall.

---

## ğŸ§© Format Support

* Supports `anchor`-based format (sequence of points)
* Tokenizer also allows `parameter` and `segmentation` formats (can be extended)

---


